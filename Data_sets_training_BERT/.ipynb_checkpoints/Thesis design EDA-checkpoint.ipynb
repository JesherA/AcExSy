{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f514b9",
   "metadata": {},
   "source": [
    "# Creating a similarity pair dataset for BERT training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3471bd",
   "metadata": {},
   "source": [
    "## SDU-AAAI-AD sentence pairs\n",
    "- To do: creat pairs with the same acronym but different meanings an label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfc274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points:50034\n",
      "number of acronym matched pairs: 60001\n",
      "Number of acronym matched pairs in final csv: 60001\n",
      "Number of acronym mismatched pairs in final csv: 50031\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading data\n",
    "sdu = pd.read_json('./BERT_datasets/train_OG.json')\n",
    "print(\"Number of data points:{}\".format(len(sdu['expansion'])))\n",
    "\n",
    "# Extracting the acronyms in words\n",
    "for index, row in sdu.iterrows():\n",
    "    acro = []\n",
    "    sdu.loc[index, 'short_form'] = row.tokens[row.acronym]\n",
    "    \n",
    "# Creating a copy and propper data types\n",
    "sdu_copy = sdu[['expansion','tokens','short_form']]\n",
    "sdu[['expansion','tokens','short_form']] = sdu[['expansion','tokens','short_form']].astype(\"string\")\n",
    "sdu_copy = sdu_copy.astype({'expansion': str,'tokens': str,'short_form': str}, errors='raise') \n",
    "\n",
    "\n",
    "# Merging the two dataframes\n",
    "sdu_combi = sdu.merge(sdu_copy, how='outer', on='expansion')\n",
    "\n",
    "\n",
    "# finding the different sentence pairs\n",
    "sdu_combi['pair'] = np.where(sdu_combi['tokens_x'] == sdu_combi['tokens_y'], 0, 1)\n",
    "sdu_combi =sdu_combi[sdu_combi['pair'] == 1]\n",
    "sdu_combi =sdu_combi.sample(n=60001)\n",
    "print('number of acronym matched pairs: {}'.format(len(sdu_combi[sdu_combi['pair'] == 1])))\n",
    "#########################\n",
    "\n",
    "# Taking a sample\n",
    "sdu_copy = sdu_copy.sample(frac=1)\n",
    "\n",
    "# creating a temporary index with shift\n",
    "sdu_copy['index1'] = sdu_copy.index + 3\n",
    "sdu['index1'] = sdu.index\n",
    "\n",
    "# Joining the two dataframes\n",
    "sdu_combi_mix = sdu.merge(sdu_copy, how='left', on='index1')\n",
    "sdu_combi_mix.dropna(inplace=True)\n",
    "sdu_combi_mix = sdu_combi_mix.drop(columns=['index1', 'expansion_y'])\n",
    "sdu_combi_mix['pair'] = np.where(sdu_combi_mix['tokens_x'] == sdu_combi_mix['tokens_y'], 1, 0)\n",
    "sdu_combi_mix = sdu_combi_mix[sdu_combi_mix['pair'] == 0]\n",
    "\n",
    "# Joining and cleaning the combined dataset\n",
    "sdu_master = pd.concat([sdu_combi,sdu_combi_mix], axis=0)\n",
    "sdu_master = sdu_master.drop(columns=['expansion_x', 'id'])\n",
    "sdu_master.reset_index(inplace=True)\n",
    "\n",
    "print('Number of acronym matched pairs in final csv: {}'.format(len(sdu_master[sdu_master['pair'] == 1])))\n",
    "print('Number of acronym mismatched pairs in final csv: {}'.format(len(sdu_master[sdu_master['pair'] == 0])))\n",
    "# print(sdu_master.head().to_string())\n",
    "\n",
    "# saving df as .csv and .json\n",
    "# sdu_master.to_csv('SDU-AAAI-AD_sentence_pairs_BERT.csv')\n",
    "# sdu_master.to_json('SDU-AAAI-AD_sentence_pairs_BERT.json')\n",
    "\n",
    "# cleaning Memmory\n",
    "del sdu_copy, sdu, sdu_combi_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa39f2c",
   "metadata": {},
   "source": [
    "## Dataset property check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a19bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Sentence pairs in the master dataset\n",
      "Sentence true pairs in the master dataset\n",
      "Sentence false pairs in the master dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset check\n",
    "sdu_master_1 = sdu_master[sdu_master['pair'] == 1]\n",
    "sdu_master_0 = sdu_master[sdu_master['pair'] == 0]\n",
    "\n",
    "print('Total number of Sentence pairs in the master dataset'.format(len(sdu_master)))\n",
    "print('Sentence true pairs in the master dataset'.format(len(sdu_master_1)))\n",
    "print('Sentence false pairs in the master dataset'.format(len(sdu_master_0)))\n",
    "\n",
    "# Hisogram of distribution\n",
    "plt.bar(x=[1,2],height=sdu_master['pair'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41d3e2",
   "metadata": {},
   "source": [
    "## Loading Veyseh sentence datasets\n",
    "- To Do, create sentence pairs for BERT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a75cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62a8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links to the data \n",
    "legal_data_link = 'https://raw.githubusercontent.com/amirveyseh/AAAI-22-SDU-shared-task-1-AE/main/data/english/legal/train.json'\n",
    "scientific_data_link = 'https://raw.githubusercontent.com/amirveyseh/AAAI-22-SDU-shared-task-1-AE/main/data/english/scientific/train.json'\n",
    "\n",
    "# scientific data\n",
    "scientific_data = pd.read_json(scientific_data_link)\n",
    "scientific_data.set_index('ID',inplace=True)\n",
    "\n",
    "# legal data\n",
    "legal_data = pd.read_json(legal_data_link)\n",
    "legal_data.set_index('ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede8df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92\\]. This selective approach led to significa...</td>\n",
       "      <td>[[91, 98]]</td>\n",
       "      <td>[[77, 89]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We conduct a case study of dialectal language ...</td>\n",
       "      <td>[[119, 122]]</td>\n",
       "      <td>[[93, 117]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An arguably better approach to representation...</td>\n",
       "      <td>[[91, 94]]</td>\n",
       "      <td>[[59, 89]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23-28, 1992   Proceedings of NAACL-HLT 2015 St...</td>\n",
       "      <td>[[71, 74], [29, 38]]</td>\n",
       "      <td>[[44, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>itly mark objects of prepositions (POBJ), poss...</td>\n",
       "      <td>[[119, 121], [35, 39], [76, 81], [95, 99], [16...</td>\n",
       "      <td>[[105, 117], [10, 33], [56, 74], [84, 93], [15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The metrics Precision (P), Recall (R),  F-scor...</td>\n",
       "      <td>[[107, 110], [83, 87]]</td>\n",
       "      <td>[[93, 105], [12, 21], [27, 33], [40, 47], [67,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>158  I. CONSTRUCT THE PROPOSED ANCHORS for Un ...</td>\n",
       "      <td>[[88, 92]]</td>\n",
       "      <td>[[65, 86]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hong Kong Laws, Sinorama, Xinhua News, and Eng...</td>\n",
       "      <td>[[132, 135]]</td>\n",
       "      <td>[[104, 130]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>uation test sets. Equal Error Rates (EER), whe...</td>\n",
       "      <td>[[54, 56], [37, 40], [49, 51], [91, 95]]</td>\n",
       "      <td>[[18, 35]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Draw Team (DT_DT); Team ? Competition (TM_CP);...</td>\n",
       "      <td>[[39, 44], [11, 16]]</td>\n",
       "      <td>[[33, 37], [0, 9]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "ID                                                      \n",
       "1   92\\]. This selective approach led to significa...   \n",
       "2   We conduct a case study of dialectal language ...   \n",
       "3    An arguably better approach to representation...   \n",
       "4   23-28, 1992   Proceedings of NAACL-HLT 2015 St...   \n",
       "5   itly mark objects of prepositions (POBJ), poss...   \n",
       "6   The metrics Precision (P), Recall (R),  F-scor...   \n",
       "7   158  I. CONSTRUCT THE PROPOSED ANCHORS for Un ...   \n",
       "8   Hong Kong Laws, Sinorama, Xinhua News, and Eng...   \n",
       "9   uation test sets. Equal Error Rates (EER), whe...   \n",
       "10  Draw Team (DT_DT); Team ? Competition (TM_CP);...   \n",
       "\n",
       "                                             acronyms  \\\n",
       "ID                                                      \n",
       "1                                          [[91, 98]]   \n",
       "2                                        [[119, 122]]   \n",
       "3                                          [[91, 94]]   \n",
       "4                                [[71, 74], [29, 38]]   \n",
       "5   [[119, 121], [35, 39], [76, 81], [95, 99], [16...   \n",
       "6                              [[107, 110], [83, 87]]   \n",
       "7                                          [[88, 92]]   \n",
       "8                                        [[132, 135]]   \n",
       "9            [[54, 56], [37, 40], [49, 51], [91, 95]]   \n",
       "10                               [[39, 44], [11, 16]]   \n",
       "\n",
       "                                           long-forms  \n",
       "ID                                                     \n",
       "1                                          [[77, 89]]  \n",
       "2                                         [[93, 117]]  \n",
       "3                                          [[59, 89]]  \n",
       "4                                          [[44, 69]]  \n",
       "5   [[105, 117], [10, 33], [56, 74], [84, 93], [15...  \n",
       "6   [[93, 105], [12, 21], [27, 33], [40, 47], [67,...  \n",
       "7                                          [[65, 86]]  \n",
       "8                                        [[104, 130]]  \n",
       "9                                          [[18, 35]]  \n",
       "10                                 [[33, 37], [0, 9]]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientific_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62118cf",
   "metadata": {},
   "source": [
    "## Creating a list with the acronyms in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e96ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientific_data = scientific_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53de69f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macronyms\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     acro\u001b[38;5;241m.\u001b[39mappend(row\u001b[38;5;241m.\u001b[39mtext[i:j])\n\u001b[0;32m----> 8\u001b[0m scientific_data\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_form\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m acro\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 716\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1688\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1739\u001b[0m         \u001b[38;5;66;03m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m         \u001b[38;5;66;03m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   1741\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1744\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1746\u001b[0m     )\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "for index, row in scientific_data.iterrows():\n",
    "    acro = []\n",
    "\n",
    "    for i, j in row['acronyms']:\n",
    "        acro.append(row.text[i:j])\n",
    "\n",
    "    \n",
    "    scientific_data.loc[index, 'short_form'] = acro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "scientific_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do's: \n",
    "# - look for a way to return the indexis of the matching short forms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd051c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = scientific_data['short_form'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3df186",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, row in scientific_data.iterrows():\n",
    "    row_index = []\n",
    "    for i in test:\n",
    "        for j in i:\n",
    "            if j in row.text:\n",
    "                row_index.append(index)\n",
    "\n",
    "                scientific_data.loc[index, 'row_index'] = row_index\n",
    "            else:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
